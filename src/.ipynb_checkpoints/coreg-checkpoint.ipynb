{
 "metadata": {
  "name": "",
  "signature": "sha256:22d1aa1b8ece5bb2b61371ab1dda19edec26721097d85acc8b2d6232de4aaca5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from time import time\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.decomposition import FactorAnalysis\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.neighbors import KNeighborsRegressor\n",
      "\n",
      "from sklearn.pipeline import make_pipeline, make_union\n",
      "from sklearn.base import TransformerMixin, BaseEstimator\n",
      "\n",
      "\n",
      "DATA_DIR = '/afs/ee.cooper.edu/user/t/a/tam8/documents/tfi/data/'\n",
      "SUBS_DIR = '/afs/ee.cooper.edu/user/t/a/tam8/documents/tfi/submissions/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "cannot import name FactorAnalysis",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-92a7330d75e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFactorAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: cannot import name FactorAnalysis"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FitlessMixin(TransformerMixin):\n",
      "    def fit_transform(self, X, y=None, **fit_params):\n",
      "        self.fit(X, y, **fit_params)\n",
      "        return self.transform(X)\n",
      "    def fit(self, X, y=None, **fit_params):\n",
      "        return self\n",
      "\n",
      "class AvgMixin(FitlessMixin, BaseEstimator):\n",
      "    def predict(self, X, y=None, **fit_params):\n",
      "        return X.mean(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = np.load(os.path.join(DATA_DIR, 'X_train.npy'))\n",
      "X_test = np.load(os.path.join(DATA_DIR, 'X_test.npy'))\n",
      "y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy'))\n",
      "\n",
      "X_all = np.r_[X_train, X_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = StandardScaler()\n",
      "scaler.fit(X_all)\n",
      "# pca = PCA(n_components=50).fit(scaler.transform(X_all))\n",
      "fa = FactorAnalysis(n_components=69).fit(scaler.transform(X_all))\n",
      "\n",
      "X_L = fa.transform(scaler.transform(X_train))[:, :-6]\n",
      "X_U = fa.transform(scaler.transform(X_test))[:, :-6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'FactorAnalysis' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-2cacb2be85ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# pca = PCA(n_components=50).fit(scaler.transform(X_all))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFactorAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_L\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'FactorAnalysis' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Init\n",
      "L = [X_L, X_L]\n",
      "y = [y_train, y_train]\n",
      "\n",
      "# n_u = len(U)  # number of unlabled observations to use (screw it)\n",
      "n_u = 10000  # number of unlabled observations to use (screw it)\n",
      "U_p = X_U[np.random.permutation(np.arange(len(X_U)))[:n_u], :]\n",
      "T = 500  # number of iterations\n",
      "k = [3, 3]    # number of neighbors\n",
      "p = [2, 5]    # minkowsky distance order\n",
      "\n",
      "# TODO: consider using distance weights\n",
      "h = [KNeighborsRegressor(n_neighbors=k_j, p=p_j).fit(L_j, y_j) \n",
      "     for L_j, y_j, k_j, p_j in zip(L, y, k, p)]\n",
      "\n",
      "h_p = [None for ii in range(len(h))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MULTIPROC\n",
      "# COREG algorithm\n",
      "# \"Semi-Supervised Regression with Co-Training\"\n",
      "# Zhi-Hua Zhou and Ming Li\n",
      "\n",
      "from joblib import Parallel, delayed  \n",
      "import multiprocessing\n",
      "num_cores = multiprocessing.cpu_count()\n",
      "\n",
      "def calc_d(x_u, h, L, y, k, p):\n",
      "    y_est = h.predict(x_u)\n",
      "    # set of (indices) k nearest neighbors of x_u\n",
      "    Omega = h.kneighbors(x_u, return_distance=False)\n",
      "    # new regressor\n",
      "    h_p = KNeighborsRegressor(n_neighbors=k, p=p)\n",
      "    h_p.fit(np.r_[L, x_u[None, :]], np.r_[y, y_est])\n",
      "    # Compare MSE\n",
      "    y_i = y[Omega[0]]\n",
      "    x_i = L[Omega[0], :]\n",
      "    se_o = (y_i - h.predict(x_i))**2\n",
      "    se_p = (y_i - h_p.predict(x_i))**2\n",
      "    d_xu = (se_o - se_p).sum(axis=0)\n",
      "    return d_xu\n",
      "\n",
      "\n",
      "start = time()\n",
      "for t in range(T):\n",
      "    print t,\n",
      "    tic = time()\n",
      "    pi = [None for ii in range(len(h))]\n",
      "    for j in range(len(h)):\n",
      "        # List of MSE diffs (per unlabeled obs)\n",
      "        d_xu_l = Parallel(n_jobs=num_cores)(delayed(calc_d)(x_u, h[j], L[j], y[j], k[j], p[j]) \n",
      "                                            for x_u in U_p) \n",
      "        d_xu_l = np.array(d_xu_l)\n",
      "        if any(d_xu_l > 0):\n",
      "            ind_top = np.argmax(d_xu_l)\n",
      "            x_top = U_p[ind_top, :]\n",
      "            y_top = h[j].predict(x_top)\n",
      "            pi[j] = (x_top[None, :], y_top)    # New pt to be added next iter\n",
      "            U_p = np.delete(U_p, (ind_top), axis=0)    # Remove pt from set\n",
      "        else:\n",
      "            pi[j] = None\n",
      "            \n",
      "    change_flag = False\n",
      "    for j in range(len(h)):\n",
      "        if pi[j]:\n",
      "            # Add new pt to the OTHER regressor's training\n",
      "            ii = (j + 1) % 2\n",
      "            L[ii] = np.append(L[ii], pi[j][0], axis=0)\n",
      "            y[ii] = np.append(y[ii], pi[j][1])\n",
      "            h[ii].fit(L[ii], y[ii]) \n",
      "            change_flag = True\n",
      "    \n",
      "    if change_flag:\n",
      "        # Replenish U_p\n",
      "        # screw it\n",
      "        pass\n",
      "    else:\n",
      "        break\n",
      "    toc = np.round(time() - tic, 2)\n",
      "    print toc,\n",
      "    sys.stdout.flush()\n",
      "        \n",
      "end = time() - start\n",
      "print 'Total time:', end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred0 = h[0].predict(X_U)\n",
      "y_pred1 = h[1].predict(X_U)\n",
      "\n",
      "y_pred = 0.5*(y_pred0 + y_pred1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub = pd.read_csv(os.path.join(DATA_DIR, 'sampleSubmission.csv'))\n",
      "sub['Prediction'] = y_pred\n",
      "sub.to_csv(os.path.join(SUBS_DIR, 'coreg3.csv'), index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import RandomForestRegressor\n",
      "# from sklearn.decomposition import FactorAnalysis\n",
      "# import matplotlib.pyplot as plt\n",
      "# %matplotlib inline\n",
      "\n",
      "\n",
      "# fa = FactorAnalysis(n_components=69).fit(scaler.transform(X_all))\n",
      "# # pca2 = PCA().fit(scaler.transform(X_all))\n",
      "\n",
      "# xx = fa.transform(scaler.transform(X_train))\n",
      "# clf = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
      "# clf.fit(xx, y_train)\n",
      "\n",
      "# plt.plot(clf.feature_importances_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}